# -- The initial number of pods that should be started at deployment of each of Confluence and Synchrony.
# Note that because Confluence requires initial manual configuration after the first pod is deployed, and before scaling
# up to additional pods, this should always be kept as 1.
replicaCount: 1

image:
  repository: atlassian/confluence-server
  pullPolicy: IfNotPresent
  # -- The docker image tag to be used. Defaults to the Chart appVersion.
  tag:

serviceAccount:
  # -- Specifies the name of the ServiceAccount to be used by the pods.
  # If not specified, but the "serviceAccount.create" flag is set, then the ServiceAccount name will be auto-generated,
  # otherwise the 'default' ServiceAccount will be used.
  name:
  # -- true if a ServiceAccount should be created, or false if it already exists
  create: true
  # -- The list of image pull secrets that should be added to the created ServiceAccount
  imagePullSecrets: []
  clusterRole:
    # -- Specifies the name of the ClusterRole that will be created if the "serviceAccount.clusterRole.create" flag is set.
    # If not specified, a name will be auto-generated.
    name:
    # -- true if a ClusterRole should be created, or false if it already exists
    create: true
  clusterRoleBinding:
    # -- Specifies the name of the ClusterRoleBinding that will be created if the "serviceAccount.clusterRoleBinding.create" flag is set
    # If not specified, a name will be auto-generated.
    name:
    # -- true if a ClusterRoleBinding should be created, or false if it already exists
    create: true

database:
  # -- The type of database being used.
  # Valid values include 'postgresql', 'mysql', 'oracle', 'mssql'.
  # If not specified, then it will need to be provided via the browser during initial startup.
  type:
  # -- The JDBC URL of the database to be used by Confluence and Synchrony, e.g. jdbc:postgresql://host:port/database
  # If not specified, then it will need to be provided via the browser during initial startup.
  url:
  credentials:
    # -- The name of the Kubernetes Secret that contains the database login credentials.
    # If specified, then the credentials will be automatically populated during Confluence setup.
    # Otherwise, they will need to be provided via the browser after initial startup.
    secretName:
    # -- The key in the Secret used to store the database login username
    usernameSecretKey: username
    # -- The key in the Secret used to store the database login password
    passwordSecretKey: password

confluence:
  service:
    # -- The port on which the Confluence Kubernetes service will listen
    port: 80
    # -- The type of Kubernetes service to use for Confluence
    type: ClusterIP
    # -- The Tomcat context path that Confluence will use. The ATL_TOMCAT_CONTEXTPATH will be set automatically
    contextPath:
  # -- Enable or disable security context in StatefulSet template spec. Enabled by default with UID 2002.
  # -- Disable when deploying to OpenShift, unless anyuid policy is attached to a service account
  securityContext:
    enabled: true
    # -- The GID used by the Confluence docker image
    gid: "2002"
  # -- The umask used by the Confluence process when it creates new files.
  # Default is 0022, which makes the new files read/writeable by the Confluence user, and readable by everyone else.
  umask: "0022"
  # -- Boolean to define whether to set home directory permissions on startup of Confluence container. Set to false to disable this behaviour.
  setPermissions: false
  ports:
    # -- The port on which the Confluence container listens for HTTP traffic
    http: 8090
    # -- The port on which the Confluence container listens for Hazelcast traffic
    hazelcast: 5701
  license:
    # -- The name of the Kubernetes Secret that contains the Confluence license key.
    # If specified, then the license will be automatically populated during Confluence setup.
    # Otherwise, it will need to be provided via the browser after initial startup.
    secretName:
    # -- The key in the Kubernetes Secret that contains the Confluence license key
    secretKey: license-key
  readinessProbe:
    # -- The initial delay (in seconds) for the Confluence container readiness probe, after which the probe will start running
    initialDelaySeconds: 10
    # -- How often (in seconds) the Confluence container readiness probe will run
    periodSeconds: 5
    # -- The number of consecutive failures of the Confluence container readiness probe before the pod fails readiness checks
    failureThreshold: 30

  accessLog:
    # -- True if access logging should be enabled.
    enabled: true
    # -- The path within the Confluence container where the local-home volume should be mounted in order to capture access logs.
    mountPath: "/opt/atlassian/confluence/logs"
    # -- The subdirectory within the local-home volume where access logs should be stored.
    localHomeSubPath: "logs"

  clustering:
    # -- Set to true if Data Center clustering should be enabled
    # This will automatically configure cluster peer discovery between cluster nodes.
    enabled: false
    # -- Set to true if the Kubernetes pod name should be used as the end-user-visible name of the Data Center cluster node.
    usePodNameAsClusterNodeName: true

  resources:
    jvm:
      # -- JVM memory arguments below are based on the defaults defined for the Confluence docker container, see:
      # https://bitbucket.org/atlassian-docker/docker-atlassian-confluence-server/src/master/#markdown-header-memory-heap-size
      #
      # -- The maximum amount of heap memory that will be used by the Confluence JVM
      maxHeap: "1g"
      # -- The minimum amount of heap memory that will be used by the Confluence JVM
      minHeap: "1g"
      # -- The memory reserved for the Confluence JVM code cache
      reservedCodeCache: "256m"
    # -- Specifies the standard Kubernetes resource requests and/or limits for the Confluence container.
    # It is important that if the memory resources are specified here, they must allow for the size of the Confluence JVM.
    # That means the maximum heap size, the reserved code cache size, plus other JVM overheads, must be accommodated.
    # Allowing for (maxHeap+codeCache)*1.5 would be an example.
    container: 
    #  limits:
    #    cpu: "1"
    #    memory: "2G"
      requests:
        cpu: "2" # -- If changing the cpu value update additional JVM arg 'ActiveProcessorCount' below
        memory: "2G"

  # -- Specifies a list of additional arguments that can be passed to the Confluence JVM, e.g. system properties
  additionalJvmArgs:
    # -- The value defined for ActiveProcessorCount should correspond to that provided for 'container.requests.cpu'
    # see: https://docs.oracle.com/en/java/javase/11/tools/java.html#GUID-3B1CE181-CD30-4178-9602-230B800D4FAE
    - -XX:ActiveProcessorCount=2

  # -- Specifies a list of additional Java libraries that should be added to the Confluence container.
  # Each item in the list should specify the name of the volume that contains the library, as well as the name of the
  # library file within that volume's root directory. Optionally, a subDirectory field can be included to specify which
  # directory in the volume contains the library file.
  additionalLibraries: []
#    - volumeName:
#      subDirectory:
#      fileName:

  # -- Specifies a list of additional Confluence plugins that should be added to the Confluence container.
  # These are specified in the same manner as the additionalLibraries field, but the files will be loaded
  # as bundled plugins rather than as libraries.
  additionalBundledPlugins: []
#    - volumeName:
#      subDirectory:
#      fileName:

  # -- Defines any additional volumes mounts for the Confluence container.
  # These can refer to existing volumes, or new volumes can be defined in volumes.additional.
  additionalVolumeMounts: []

  # -- Defines any additional environment variables to be passed to the Confluence container.
  # See https://hub.docker.com/r/atlassian/confluence-server for supported variables.
  additionalEnvironmentVariables: []

  jvmDebug:
    # -- If set to true, Confluence JVM will be started with debugging port 5005 open.
    enabled: false

synchrony:
  # -- True if Synchrony (i.e. collaborative editing) should be enabled.
  # This will result in a separate StatefulSet and Service to be created for Synchrony.
  # If disabled, then collaborative editing will be disabled in Confluence.
  enabled: false
  service:
    # -- The port on which the Synchrony Kubernetes service will listen
    port: 80
    # -- The type of Kubernetes service to use for Synchrony
    type: ClusterIP
  ports:
    # -- The port on which the Synchrony container listens for HTTP traffic
    http: 8091
    # -- The port on which the Synchrony container listens for Hazelcast traffic
    hazelcast: 5701
  readinessProbe:
    # -- The initial delay (in seconds) for the Synchrony container readiness probe, after which the probe will start running
    initialDelaySeconds: 5
    # -- How often (in seconds) the Synchrony container readiness probe will run
    periodSeconds: 1
    # -- The number of consecutive failures of the Synchrony container readiness probe before the pod fails readiness checks
    failureThreshold: 30
  # -- The base URL of the Synchrony service.
  # This will be the URL that users' browsers will be given to communicate with Synchrony, as well as the URL that the
  # Confluence service will use to communicate directly with Synchrony, so the URL must be resovable both from inside and
  # outside the Kubernetes cluster.
  ingressUrl:
  # -- Specifies a list of additional Java libraries that should be added to the Synchrony container.
  # Each item in the list should specify the name of the volume which contain the library, as well as the name of the
  # library file within that volume's root directory. Optionally, a subDirectory field can be included to specify which
  # directory in the volume contains the library file.
  additionalLibraries: []
#    - volumeName:
#      subDirectory:
#      fileName:

ingress:
  # -- True if an Ingress Resource should be created.
  create: false
  # -- True if the created Ingress Resource is to use the Kubernetes ingress-nginx controller:
  # https://kubernetes.github.io/ingress-nginx/
  # This will populate the Ingress Resource with annotations for the Kubernetes ingress-nginx controller.
  # Set to false if a different controller is to be used, in which case the appropriate annotations for that
  # controller need to be specified.
  nginx: true
  # -- The max body size to allow. Requests exceeding this size will result
  # in an 413 error being returned to the client.
  # https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/#custom-max-body-size
  maxBodySize: 250m
  # -- The fully-qualified hostname of the Ingress Resource.
  host:
  # -- The base path for the ingress rule.
  path: "/"
  # -- The custom annotations that should be applied to the Ingress 
  # Resource when not using the Kubernetes ingress-nginx controller.
  annotations: {}
  # -- True if the browser communicates with the application over HTTPS.
  https: true
  # -- Secret that contains a TLS private key and certificate.
  # Optional if Ingress Controller is configured to use one secret for all ingresses
  tlsSecretName:

fluentd:
  # -- True if the Fluentd sidecar should be added to each pod
  enabled: false
  # -- True if a custom config should be used for Fluentd
  customConfigFile: false
  # -- Custom fluent.conf file
  # fluent.conf: |
  fluentdCustomConfig: {}
  # fluent.conf: |
  #   <source>
  #     @type tail
  #     <parse>
  #     @type multiline
  #     format_firstline /\d{4}-\d{1,2}-\d{1,2}/
  #     </parse>
  #     path /opt/atlassian/confluence/logs/access_log.*
  #     pos_file /tmp/confluencelog.pos
  #     tag confluence-access-logs
  #   </source>

 # -- The name of the image containing the Fluentd sidecar
  imageName: fluent/fluentd-kubernetes-daemonset:v1.11.5-debian-elasticsearch7-1.2
  # -- The port on which the Fluentd sidecar will listen
  httpPort: 9880
  elasticsearch:
    # -- True if Fluentd should send all log events to an Elasticsearch service.
    enabled: true
    # -- The hostname of the Elasticsearch service that Fluentd should send logs to.
    hostname: elasticsearch
    # -- The prefix of the Elasticsearch index name that will be used
    indexNamePrefix: confluence
  # -- Specify custom volumes to be added to Fluentd container (e.g. more log sources)
  extraVolumes: []
  # - name: local-home
  #   mountPath: /opt/atlassian/confluence/logs
  #   subPath: log
  #   readOnly: true
# -- Specify additional annotations to be added to all Confluence and Synchrony pods
podAnnotations: {}
#  "name": "value"

volumes:
  localHome:
    persistentVolumeClaim:
      # -- If true, then a PersistentVolumeClaim will be created for each local-home volume.
      create: false
      # -- Specifies the name of the storage class that should be used for the local-home volume claim.
      storageClassName:
      # -- Specifies the standard Kubernetes resource requests and/or limits for the local-home volume claims.
      resources:
        requests:
          storage: 1Gi
    # -- When persistentVolumeClaim.create is false, then this value can be used to define a standard Kubernetes
    # volume that will be used for the local-home volumes. If not defined, then defaults to an emptyDir volume.
    customVolume: {}
    # -- The path within the Confluence container where the local-home volume should be mounted.
    mountPath: "/var/atlassian/application-data/confluence"
  sharedHome:
    persistentVolumeClaim:
      # -- If true, then a PersistentVolumeClaim will be created for the shared-home volume.
      create: false
      # -- Specifies the name of the storage class that should be used for the shared-home volume claim.
      storageClassName:
      # -- Specifies the standard Kubernetes resource requests and/or limits for the shared-home volume claims.
      resources:
        requests:
          storage: 1Gi
    # -- When persistentVolumeClaim.create is false, then this value can be used to define a standard Kubernetes
    # volume, which will be used for the shared-home volume. If not defined, then defaults to an emptyDir (i.e. unshared) volume.
    customVolume: {}
    # -- Specifies the path in the Confluence container to which the shared-home volume will be mounted.
    mountPath: "/var/atlassian/application-data/shared-home"
    # -- Specifies the sub-directory of the shared-home volume that will be mounted in to the Confluence container.
    subPath:
    nfsPermissionFixer:
      # -- If enabled, this will alter the shared-home volume's root directory so that Confluence can write to it.
      # This is a workaround for a Kubernetes bug affecting NFS volumes: https://github.com/kubernetes/examples/issues/260
      enabled: false
      # -- The path in the initContainer where the shared-home volume will be mounted
      mountPath: /shared-home
      # -- By default, the fixer will change the group ownership of the volume's root directory to match the Confluence
      # container's GID (2002), and then ensures the directory is group-writeable. If this is not the desired behaviour,
      # command used can be specified here.
      command:
  # -- Defines additional volumes that should be applied to all Confluence pods.
  # Note that this will not create any corresponding volume mounts;
  # those needs to be defined in confluence.additionalVolumeMounts
  additional: []

# -- Standard Kubernetes node-selectors that will be applied to all Confluence and Synchrony pods
nodeSelector: {}

# -- Standard Kubernetes tolerations that will be applied to all Confluence and Synchrony pods
tolerations: []

# -- Standard Kubernetes affinities that will be applied to all Confluence and Synchrony pods
affinity: {}

# -- Additional container definitions that will be added to all Confluence pods
additionalContainers: []

# -- Additional initContainer definitions that will be added to all Confluence pods
additionalInitContainers: []

# -- Additional labels that should be applied to all resources
additionalLabels: {}

# -- Additional existing ConfigMaps and Secrets not managed by Helm that should be mounted into server container
# configMap and secret are two available types (camelCase is important!)
# mountPath is a destination directory in a container and key is file name
# name references existing ConfigMap or secret name. VolumeMount and Volumes are added with this name and index position,
# for example, custom-config-0, keystore-2
additionalFiles: []

#  - name: custom-config
#    type: configMap
#    key: log4j.properties
#    mountPath:  /var/atlassian
#  - name: custom-config
#    type: configMap
#    key: web.xml
#    mountPath: /var/atlassian
#  - name: keystore
#    type: secret
#    key: keystore.jks
#    mountPath: /var/ssl

# -- Additional host aliases for each pod, equivalent to adding them to the /etc/hosts file. See
# https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/ for more
# information.
additionalHosts: []
#  - ip: "127.0.0.1"
#    hostnames:
#    - "foo.local"
#    - "bar.local"
